<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="HomogeneousPoissonEncoder" href="inferno.neural.HomogeneousPoissonEncoder.html" /><link rel="prev" title="LinearLateral" href="inferno.neural.LinearLateral.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2023.09.10 -->
        <title>Conv2D - Inferno</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/shape.css?v=23eccd26" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Inferno</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">Inferno</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../inferno.html">inferno</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neural.html">inferno.neural</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neural-functional.html">inferno.neural.functional</a></li>
<li class="toctree-l2"><a class="reference internal" href="../learn.html">inferno.learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../learn-functional.html">inferno.learn.functional</a></li>
<li class="toctree-l2"><a class="reference internal" href="../observe.html">inferno.observe</a></li>
<li class="toctree-l2"><a class="reference internal" href="../typing.html">inferno.typing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stats.html">inferno.dists</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../guide/index.html">Guidebook</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Guidebook</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../guide/mathematics.html">Mathematical Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../guide/neurons.html">Neurons and Neuronal Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../guide/considerations.html">Pragmatic Considerations</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../zoo/index.html">Model and Method Zoo</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Model and Method Zoo</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../zoo/neurons-adaptation.html">Neuronal Adaptation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../zoo/neurons-linear.html">Neuron Models, Linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../zoo/neurons-nonlinear.html">Neuron Models, Nonlinear</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../zoo/synapses-current.html">Synapse Models, Current-Based</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../zoo/synapses-conductance.html">Synapse Models, Conductance-Based</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../zoo/learning-stdp.html">STDP-Like Learning Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../zoo/learning-resume.html">ReSuMe-Like Learning Methods</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="conv2d">
<h1>Conv2D<a class="headerlink" href="#conv2d" title="Link to this heading">#</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="inferno.neural.Conv2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Conv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">height</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">width</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">filters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synapse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="inferno.neural.SynapseConstructor.html#inferno.neural.SynapseConstructor" title="inferno.neural.base.SynapseConstructor"><span class="pre">SynapseConstructor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_init</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="inferno.typing.OneToOne.html#inferno.typing.OneToOne" title="inferno.typing.functional.OneToOne"><span class="pre">OneToOne</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_init</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="inferno.typing.OneToOne.html#inferno.typing.OneToOne" title="inferno.typing.functional.OneToOne"><span class="pre">OneToOne</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay_init</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="inferno.typing.OneToOne.html#inferno.typing.OneToOne" title="inferno.typing.functional.OneToOne"><span class="pre">OneToOne</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/inferno/neural/connections/conv.html#Conv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#inferno.neural.Conv2D" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="inferno.neural.connections.mixins.WeightBiasDelayMixin.html#inferno.neural.connections.mixins.WeightBiasDelayMixin" title="inferno.neural.connections.mixins.WeightBiasDelayMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">WeightBiasDelayMixin</span></code></a>, <a class="reference internal" href="inferno.neural.Connection.html#inferno.neural.Connection" title="inferno.neural.base.Connection"><code class="xref py py-class docutils literal notranslate"><span class="pre">Connection</span></code></a></p>
<p>Convolutional connection along two spatial dimensions with separate input planes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>height</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – height of the expected inputs.</p></li>
<li><p><strong>width</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – width of the expected inputs.</p></li>
<li><p><strong>channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – number of channels in the input tensor.</p></li>
<li><p><strong>filters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – number of convolutional filters (channels of the output tensor).</p></li>
<li><p><strong>step_time</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – length of a simulation time step, in <span class="math notranslate nohighlight">\(\text{ms}\)</span>.</p></li>
<li><p><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>]</em>) – size of the convolution kernel.</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – stride of the convolution.
Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – amount of zero padding added to
height and width. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – dilation of the convolution.
Defaults to 1.</p></li>
<li><p><strong>synapse</strong> (<a class="reference internal" href="inferno.neural.SynapseConstructor.html#inferno.neural.SynapseConstructor" title="inferno.neural.SynapseConstructor"><em>SynapseConstructor</em></a>) – partial constructor for inner <a class="reference internal" href="inferno.neural.Synapse.html#inferno.neural.Synapse" title="inferno.neural.Synapse"><code class="xref py py-class docutils literal notranslate"><span class="pre">Synapse</span></code></a>.</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – if the connection should support
learnable additive bias. Defaults to False.</p></li>
<li><p><strong>delay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em> | </em><em>None</em><em>, </em><em>optional</em>) – maximum supported delay length, in
<span class="math notranslate nohighlight">\(\text{ms}\)</span>, excludes delays when None. Defaults to None.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – size of input batches for simualtion. Defaults to 1.</p></li>
<li><p><strong>weight_init</strong> (<a class="reference internal" href="inferno.typing.OneToOne.html#inferno.typing.OneToOne" title="inferno.typing.OneToOne"><em>OneToOne</em></a><em>[</em><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a><em>] </em><em>| </em><em>None</em><em>, </em><em>optional</em>) – initializer for weights.
Defaults to None.</p></li>
<li><p><strong>bias_init</strong> (<a class="reference internal" href="inferno.typing.OneToOne.html#inferno.typing.OneToOne" title="inferno.typing.OneToOne"><em>OneToOne</em></a><em>[</em><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a><em>] </em><em>| </em><em>None</em><em>, </em><em>optional</em>) – initializer for biases.
Defaults to None.</p></li>
<li><p><strong>delay_init</strong> (<a class="reference internal" href="inferno.typing.OneToOne.html#inferno.typing.OneToOne" title="inferno.typing.OneToOne"><em>OneToOne</em></a><em>[</em><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a><em>] </em><em>| </em><em>None</em><em>, </em><em>optional</em>) – initializer for delays.
Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="tensorshape admonition">
<p class="admonition-title">Shape</p>
<p><code class="docutils literal notranslate"><span class="pre">Conv2D.weight</span></code>, <code class="docutils literal notranslate"><span class="pre">Conv2D.delay</span></code>:</p>
<p><span class="math notranslate nohighlight">\(F \times C \times H \times W\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">Conv2D.bias</span></code>:</p>
<p><span class="math notranslate nohighlight">\(F\)</span></p>
<dl class="simple">
<dt>Where:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(F\)</span> is the number of filters (output channels).</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span> is the number of input channels.</p></li>
<li><p><span class="math notranslate nohighlight">\(kH\)</span> is the kernel height.</p></li>
<li><p><span class="math notranslate nohighlight">\(kW\)</span> is the kernel width.</p></li>
</ul>
</dd>
</dl>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <code class="docutils literal notranslate"><span class="pre">delay</span></code> is None, no <code class="docutils literal notranslate"><span class="pre">delay_</span></code> parameter is created and altering the
maximum delay of <code class="xref py py-attr docutils literal notranslate"><span class="pre">synapse</span></code> will have no effect. Setting to 0 will
create and register a <code class="docutils literal notranslate"><span class="pre">delay_</span></code> parameter but not use delays unless it is
later changed.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="docutils literal notranslate"><span class="pre">weight_init</span></code> or <code class="docutils literal notranslate"><span class="pre">bias_init</span></code> are None, <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> are,
respectively, initialized as uniform random values over the interval
<span class="math notranslate nohighlight">\([0, 1)\)</span> using <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.rand.html#torch.rand" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.rand()</span></code></a>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">delay_init</span></code> is None, <code class="docutils literal notranslate"><span class="pre">delay</span></code> is initialized as zeros using
<a class="reference external" href="https://pytorch.org/docs/master/generated/torch.rand.html#torch.rand" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.rand()</span></code></a>.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The added padding is applied after the synapse. Inputs must still be of uniform
size. Only zero padding is supported, if another type of padding is required,
it should be performed before being inputted to the connection.</p>
</div>
<p class="rubric">Methods</p>
<dl class="py method">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.clear">
<span class="sig-name descname"><span class="pre">clear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#inferno.neural.Conv2D.clear" title="Link to this definition">#</a></dt>
<dd><p>Resets the state of the connection.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This calls the method <a class="reference internal" href="inferno.neural.Synapse.html#inferno.neural.Synapse.clear" title="inferno.neural.Synapse.clear"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Synapse.clear()</span></code></a> on <code class="xref py py-attr docutils literal notranslate"><span class="pre">synapse</span></code>,
assuming the connection itself has no clearable state. Keyword arguments
are passed through.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../../_modules/inferno/neural/connections/conv.html#Conv2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#inferno.neural.Conv2D.forward" title="Link to this definition">#</a></dt>
<dd><p>Generates connection output from inputs, after passing through the synapse.</p>
<p>Outputs are determined as the learned two-dimensional convolution applied to
synaptic currents, after new input is applied to the synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*inputs</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a>) – inputs to the connection.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>outputs from the connection.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a></p>
</dd>
</dl>
<div class="tensorshape admonition">
<p class="admonition-title">Shape</p>
<p><code class="docutils literal notranslate"><span class="pre">*inputs</span></code>:</p>
<p><span class="math notranslate nohighlight">\(B \times C \times H \times W\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">return</span></code>:</p>
<p><span class="math notranslate nohighlight">\(B \times F \times H_\text{out} \times W_\text{out}\)</span></p>
<dl class="simple">
<dt>Where:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(B\)</span> is the batch size.</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span> is the number of input channels.</p></li>
<li><p><span class="math notranslate nohighlight">\(H\)</span> is the input height.</p></li>
<li><p><span class="math notranslate nohighlight">\(W\)</span> is the input width.</p></li>
<li><p><span class="math notranslate nohighlight">\(F\)</span> is the number of filters (output channels).</p></li>
<li><p><span class="math notranslate nohighlight">\(H_\text{out}\)</span> is the output height.</p></li>
<li><p><span class="math notranslate nohighlight">\(W_\text{out}\)</span> is the output width.</p></li>
</ul>
</dd>
</dl>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">*inputs</span></code> are reshaped using <a class="reference internal" href="#inferno.neural.Conv2D.like_synaptic" title="inferno.neural.Conv2D.like_synaptic"><code class="xref py py-meth docutils literal notranslate"><span class="pre">like_synaptic()</span></code></a> then passed to
py:meth:<cite>Synapse.forward</cite> of <code class="xref py py-attr docutils literal notranslate"><span class="pre">synapse</span></code>. Keyword arguments are
also passed through.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>The formulae for output height and width are detailed in the documentation
for <a class="reference internal" href="#inferno.neural.Conv2D.outshape" title="inferno.neural.Conv2D.outshape"><code class="xref py py-attr docutils literal notranslate"><span class="pre">outshape</span></code></a>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.like_input">
<span class="sig-name descname"><span class="pre">like_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../../_modules/inferno/neural/connections/conv.html#Conv2D.like_input"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#inferno.neural.Conv2D.like_input" title="Link to this definition">#</a></dt>
<dd><p>Reshapes data like synapse input to connection input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a>) – data shaped like synapse input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>reshaped data.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a></p>
</dd>
</dl>
<div class="tensorshape admonition">
<p class="admonition-title">Shape</p>
<p><code class="docutils literal notranslate"><span class="pre">data</span></code>:</p>
<p><span class="math notranslate nohighlight">\(B \times (C \cdot kH \cdot kW) \times (H_\text{out}
\cdot W_\text{out})\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">return</span></code>:</p>
<p><span class="math notranslate nohighlight">\(B \times C \times H \times W\)</span></p>
<dl class="simple">
<dt>Where:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(B\)</span> is the batch size.</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span> is the number of input channels.</p></li>
<li><p><span class="math notranslate nohighlight">\(kH\)</span> is the kernel height.</p></li>
<li><p><span class="math notranslate nohighlight">\(kW\)</span> is the kernel width.</p></li>
<li><p><span class="math notranslate nohighlight">\(H_\text{out}\)</span> is the output height.</p></li>
<li><p><span class="math notranslate nohighlight">\(W_\text{out}\)</span> is the output width.</p></li>
<li><p><span class="math notranslate nohighlight">\(H\)</span> is the input height.</p></li>
<li><p><span class="math notranslate nohighlight">\(W\)</span> is the input width.</p></li>
</ul>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.like_synaptic">
<span class="sig-name descname"><span class="pre">like_synaptic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../../_modules/inferno/neural/connections/conv.html#Conv2D.like_synaptic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#inferno.neural.Conv2D.like_synaptic" title="Link to this definition">#</a></dt>
<dd><p>Reshapes data like connection input to synapse input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a>) – data shaped like connection input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>reshaped data.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a></p>
</dd>
</dl>
<div class="tensorshape admonition">
<p class="admonition-title">Shape</p>
<p><code class="docutils literal notranslate"><span class="pre">data</span></code>:</p>
<p><span class="math notranslate nohighlight">\(B \times C \times H \times W\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">return</span></code>:</p>
<p><span class="math notranslate nohighlight">\(B \times (C \cdot kH \cdot kW) \times (H_\text{out}
\cdot W_\text{out})\)</span></p>
<dl class="simple">
<dt>Where:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(B\)</span> is the batch size.</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span> is the number of input channels.</p></li>
<li><p><span class="math notranslate nohighlight">\(H\)</span> is the input height.</p></li>
<li><p><span class="math notranslate nohighlight">\(W\)</span> is the input width.</p></li>
<li><p><span class="math notranslate nohighlight">\(kH\)</span> is the kernel height.</p></li>
<li><p><span class="math notranslate nohighlight">\(kW\)</span> is the kernel width.</p></li>
<li><p><span class="math notranslate nohighlight">\(H_\text{out}\)</span> is the output height.</p></li>
<li><p><span class="math notranslate nohighlight">\(W_\text{out}\)</span> is the output width.</p></li>
</ul>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.postsyn_receptive">
<span class="sig-name descname"><span class="pre">postsyn_receptive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../../_modules/inferno/neural/connections/conv.html#Conv2D.postsyn_receptive"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#inferno.neural.Conv2D.postsyn_receptive" title="Link to this definition">#</a></dt>
<dd><p>Reshapes data like connection output for pre-post learning methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a>) – data shaped like output of <a class="reference internal" href="#inferno.neural.Conv2D.forward" title="inferno.neural.Conv2D.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>reshaped data.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a></p>
</dd>
</dl>
<div class="tensorshape admonition">
<p class="admonition-title">Shape</p>
<p><code class="docutils literal notranslate"><span class="pre">data</span></code>:</p>
<p><span class="math notranslate nohighlight">\(B \times F \times H_\text{out} \times W_\text{out}\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">return</span></code>:</p>
<p><span class="math notranslate nohighlight">\(B \times F \times 1 \times 1 \times 1 \times
(H_\text{out} \cdot W_\text{out})\)</span></p>
<dl class="simple">
<dt>Where:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(B\)</span> is the batch size.</p></li>
<li><p><span class="math notranslate nohighlight">\(F\)</span> is the number of filters (output channels).</p></li>
<li><p><span class="math notranslate nohighlight">\(H_\text{out}\)</span> is the output height.</p></li>
<li><p><span class="math notranslate nohighlight">\(W_\text{out}\)</span> is the output width.</p></li>
</ul>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.presyn_receptive">
<span class="sig-name descname"><span class="pre">presyn_receptive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../../_modules/inferno/neural/connections/conv.html#Conv2D.presyn_receptive"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#inferno.neural.Conv2D.presyn_receptive" title="Link to this definition">#</a></dt>
<dd><p>Reshapes data like the synapse state for pre-post learning methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a>) – data shaped like output of <a class="reference internal" href="#inferno.neural.Conv2D.like_synaptic" title="inferno.neural.Conv2D.like_synaptic"><code class="xref py py-meth docutils literal notranslate"><span class="pre">like_synaptic()</span></code></a>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>reshaped data.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a></p>
</dd>
</dl>
<div class="tensorshape admonition">
<p class="admonition-title">Shape</p>
<p><code class="docutils literal notranslate"><span class="pre">data</span></code>:</p>
<p><span class="math notranslate nohighlight">\(B \times (C \cdot kH \cdot kW) \times (H_\text{out}
\cdot W_\text{out}) \times [F]\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">return</span></code>:</p>
<p><span class="math notranslate nohighlight">\(B \times F \times C \times kH \times kW \times
(H_\text{out} \cdot W_\text{out})\)</span></p>
<p>or</p>
<p><span class="math notranslate nohighlight">\(B \times 1 \times C \times kH \times kW \times
(H_\text{out} \cdot W_\text{out})\)</span></p>
<dl class="simple">
<dt>Where:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(B\)</span> is the batch size.</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span> is the number of input channels.</p></li>
<li><p><span class="math notranslate nohighlight">\(kH\)</span> is the kernel height.</p></li>
<li><p><span class="math notranslate nohighlight">\(kW\)</span> is the kernel width.</p></li>
<li><p><span class="math notranslate nohighlight">\(H_\text{out}\)</span> is the output height.</p></li>
<li><p><span class="math notranslate nohighlight">\(W_\text{out}\)</span> is the output width.</p></li>
<li><p><span class="math notranslate nohighlight">\(F\)</span> is the number of filters (output channels).</p></li>
</ul>
</dd>
</dl>
</div>
</dd></dl>

<p class="rubric">Properties</p>
<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.bias">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.bias" title="Link to this definition">#</a></dt>
<dd><p>Learnable connection biases.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a>) – new biases.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>present biases, if any.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.biased">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">biased</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.biased" title="Link to this definition">#</a></dt>
<dd><p>If the connection has learnable biases.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>if the connection has learnable biases.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.binshape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">binshape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#inferno.neural.Conv2D.binshape" title="Link to this definition">#</a></dt>
<dd><p>Shape of inputs to the connection, including the batch dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>shape of inputs to the connection.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.boutshape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">boutshape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#inferno.neural.Conv2D.boutshape" title="Link to this definition">#</a></dt>
<dd><p>Shape of outputs from the connection, including the batch dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>shape of outputs from the connection.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.bsize">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bsize</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.bsize" title="Link to this definition">#</a></dt>
<dd><p>Batch size of the connection.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – new batch size.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>current batch size.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This calls the property <code class="xref py py-attr docutils literal notranslate"><span class="pre">Synapse.bsize</span></code> on <code class="xref py py-attr docutils literal notranslate"><span class="pre">synapse</span></code>,
assuming the connection has no batch size dependent state.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.delay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">delay</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.delay" title="Link to this definition">#</a></dt>
<dd><p>Learnable connection delays.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a>) – new delays.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>present delays, if any.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.delayedby">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">delayedby</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.delayedby" title="Link to this definition">#</a></dt>
<dd><p>Maxmimum valid learned delay, in milliseconds.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>maxmimum valid learned delays.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This calls the property <a class="reference internal" href="inferno.neural.Synapse.html#inferno.neural.Synapse.delay" title="inferno.neural.Synapse.delay"><code class="xref py py-attr docutils literal notranslate"><span class="pre">Synapse.delay</span></code></a> on <code class="xref py py-attr docutils literal notranslate"><span class="pre">synapse</span></code>
if the connections has delays, otherwise returns None.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.dt">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dt</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.dt" title="Link to this definition">#</a></dt>
<dd><p>Length of the simulation time step, in milliseconds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – new length of the simulation time step.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>current length of the simulation time step.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This calls the property <code class="xref py py-attr docutils literal notranslate"><span class="pre">dt</span></code> on <code class="xref py py-attr docutils literal notranslate"><span class="pre">synapse</span></code>,
assuming the connection has no step time dependent state.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.inshape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inshape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#inferno.neural.Conv2D.inshape" title="Link to this definition">#</a></dt>
<dd><p>Shape of inputs to the connection, excluding the batch dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>shape of inputs to the connection.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Resulting tuple will be:</p>
<p><span class="math notranslate nohighlight">\((C, H, W)\)</span></p>
<dl class="simple">
<dt>Where:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(C\)</span> is the number of input channels.</p></li>
<li><p><span class="math notranslate nohighlight">\(H\)</span> is the input height.</p></li>
<li><p><span class="math notranslate nohighlight">\(W\)</span> is the input width.</p></li>
</ul>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.insize">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">insize</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.insize" title="Link to this definition">#</a></dt>
<dd><p>Number of inputs to the connection, excluding the batch dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>number of inputs to the connection.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a></p>
</dd>
</dl>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This is a cached property based on <a class="reference internal" href="#inferno.neural.Conv2D.inshape" title="inferno.neural.Conv2D.inshape"><code class="xref py py-attr docutils literal notranslate"><span class="pre">inshape</span></code></a>. When subclassing,
if the computed value for <code class="docutils literal notranslate"><span class="pre">inshape</span></code> is changed, <code class="docutils literal notranslate"><span class="pre">insize</span></code> must be
deleted to refresh the cache.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.outshape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">outshape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#inferno.neural.Conv2D.outshape" title="Link to this definition">#</a></dt>
<dd><p>Shape of outputs from the connection, excluding the batch dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>shape of outputs from the connection.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Resulting tuple will be:</p>
<p><span class="math notranslate nohighlight">\((F, H_\text{out}, W_\text{out})\)</span></p>
<p>Where:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    H_\text{out} &amp;= \left\lfloor \frac{H + 2 \times p_H - d_H
    \times (k_H - 1) - 1}{s_H} + 1 \right\rfloor \\
    W_\text{out} &amp;= \left\lfloor \frac{W + 2 \times p_W - d_W
    \times (k_W - 1) - 1}{s_W} + 1 \right\rfloor
\end{align*}\end{split}\]</div>
</div>
<dl class="simple">
<dt>And:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(F\)</span> is the number of filters (output channels).</p></li>
<li><p><span class="math notranslate nohighlight">\((H, W)\)</span> are the input height and width.</p></li>
<li><p><span class="math notranslate nohighlight">\((pH, pW)\)</span> are the per-side padding height and width.</p></li>
<li><p><span class="math notranslate nohighlight">\((dH, dW)\)</span> are the dilation height and width.</p></li>
<li><p><span class="math notranslate nohighlight">\((kH, kW)\)</span> are the kernel height and width.</p></li>
<li><p><span class="math notranslate nohighlight">\((sH, sW)\)</span> are the stride height and width.</p></li>
</ul>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.outsize">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">outsize</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.outsize" title="Link to this definition">#</a></dt>
<dd><p>Number of outputs from the connection, excluding the batch dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>number of outputs from the connection.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a></p>
</dd>
</dl>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This is a cached property based on <a class="reference internal" href="#inferno.neural.Conv2D.outshape" title="inferno.neural.Conv2D.outshape"><code class="xref py py-attr docutils literal notranslate"><span class="pre">outshape</span></code></a>. When subclassing,
if the computed value for <code class="docutils literal notranslate"><span class="pre">outshape</span></code> is changed, <code class="docutils literal notranslate"><span class="pre">outsize</span></code> must be
deleted to refresh the cache.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.selector">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">selector</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.selector" title="Link to this definition">#</a></dt>
<dd><p>Learned delays as a selector for synaptic currents and delays.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>delay selector if the connection has learnable delays.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a> | None</p>
</dd>
</dl>
<div class="tensorshape admonition">
<p class="admonition-title">Shape</p>
<p><span class="math notranslate nohighlight">\(B \times (C \cdot kH \cdot kW) \times (H_\text{out}
\cdot W_\text{out}) \times F\)</span></p>
<dl class="simple">
<dt>Where:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(B\)</span> is the batch size.</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span> is the number of input channels.</p></li>
<li><p><span class="math notranslate nohighlight">\(kH\)</span> is the kernel height.</p></li>
<li><p><span class="math notranslate nohighlight">\(kW\)</span> is the kernel width.</p></li>
<li><p><span class="math notranslate nohighlight">\(H_\text{out}\)</span> is the output height.</p></li>
<li><p><span class="math notranslate nohighlight">\(W_\text{out}\)</span> is the output width.</p></li>
<li><p><span class="math notranslate nohighlight">\(F\)</span> is the number of filters (output channels).</p></li>
</ul>
</dd>
</dl>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This operation relies upon <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.Tensor.expand.html#torch.Tensor.expand" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.expand()</span></code></a>, and
consequentially multiple elements may reference the same underlying
memory.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.syncurrent">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">syncurrent</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.syncurrent" title="Link to this definition">#</a></dt>
<dd><p>Currents from the synapse at the time last used by the connection.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>last used  synaptic currents.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">delayed</span></code> is None, this should return the most recent synaptic
currents, otherwise it should return those indexed by <a class="reference internal" href="#inferno.neural.Conv2D.delay" title="inferno.neural.Conv2D.delay"><code class="xref py py-attr docutils literal notranslate"><span class="pre">delay</span></code></a>.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.synspike">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">synspike</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.synspike" title="Link to this definition">#</a></dt>
<dd><p>Spikes to the synapse at the time last used by the connection.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>delay-offset synaptic spikes.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="inferno.neural.Conv2D.weight">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">weight</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#inferno.neural.Conv2D.weight" title="Link to this definition">#</a></dt>
<dd><p>Learnable connection weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))"><em>torch.Tensor</em></a>) – new weights.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>present weights.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (2.1.0a0+gitbe0b12e ))">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="inferno.neural.HomogeneousPoissonEncoder.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">HomogeneousPoissonEncoder</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="inferno.neural.LinearLateral.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">LinearLateral</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, MD
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Conv2D</a><ul>
<li><a class="reference internal" href="#inferno.neural.Conv2D"><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code></a><ul>
<li><a class="reference internal" href="#inferno.neural.Conv2D.clear"><code class="docutils literal notranslate"><span class="pre">Conv2D.clear()</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.forward"><code class="docutils literal notranslate"><span class="pre">Conv2D.forward()</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.like_input"><code class="docutils literal notranslate"><span class="pre">Conv2D.like_input()</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.like_synaptic"><code class="docutils literal notranslate"><span class="pre">Conv2D.like_synaptic()</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.postsyn_receptive"><code class="docutils literal notranslate"><span class="pre">Conv2D.postsyn_receptive()</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.presyn_receptive"><code class="docutils literal notranslate"><span class="pre">Conv2D.presyn_receptive()</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.bias"><code class="docutils literal notranslate"><span class="pre">Conv2D.bias</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.biased"><code class="docutils literal notranslate"><span class="pre">Conv2D.biased</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.binshape"><code class="docutils literal notranslate"><span class="pre">Conv2D.binshape</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.boutshape"><code class="docutils literal notranslate"><span class="pre">Conv2D.boutshape</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.bsize"><code class="docutils literal notranslate"><span class="pre">Conv2D.bsize</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.delay"><code class="docutils literal notranslate"><span class="pre">Conv2D.delay</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.delayedby"><code class="docutils literal notranslate"><span class="pre">Conv2D.delayedby</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.dt"><code class="docutils literal notranslate"><span class="pre">Conv2D.dt</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.inshape"><code class="docutils literal notranslate"><span class="pre">Conv2D.inshape</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.insize"><code class="docutils literal notranslate"><span class="pre">Conv2D.insize</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.outshape"><code class="docutils literal notranslate"><span class="pre">Conv2D.outshape</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.outsize"><code class="docutils literal notranslate"><span class="pre">Conv2D.outsize</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.selector"><code class="docutils literal notranslate"><span class="pre">Conv2D.selector</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.syncurrent"><code class="docutils literal notranslate"><span class="pre">Conv2D.syncurrent</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.synspike"><code class="docutils literal notranslate"><span class="pre">Conv2D.synspike</span></code></a></li>
<li><a class="reference internal" href="#inferno.neural.Conv2D.weight"><code class="docutils literal notranslate"><span class="pre">Conv2D.weight</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>